{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# # # this may cause DisentenglementTargetManager to reimported, losing all the data e.g. configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"DeJavu Serif\"\n",
    "plt.rcParams[\"font.serif\"] = [\"Times New Roman\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/kemal.inecik/tools/apps/mamba/envs/tardis_env/lib/python3.10/site-packages/umap/__init__.py:9: ImportWarning: Tensorflow not installed; ParametricUMAP will be unavailable\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "    import os\n",
    "    import sys\n",
    "    import gc\n",
    "    import warnings\n",
    "    import anndata as ad\n",
    "    import scanpy as sc\n",
    "    import copy\n",
    "    import torch\n",
    "    from pathlib import Path\n",
    "    import networkx as nx\n",
    "    from sklearn.neighbors import kneighbors_graph\n",
    "    import numpy as np\n",
    "    import rapids_singlecell as rsc\n",
    "    import scanpy as sc\n",
    "    import cupyx as cpx\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import scipy.stats\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.formula.api import ols\n",
    "    import scib\n",
    "    import scib_metrics\n",
    "    \n",
    "    sys.path.append(\"/home/icb/kemal.inecik/work/codes/tardis\")\n",
    "    import tardis\n",
    "    tardis.config = tardis.config_server\n",
    "    \n",
    "    sc.settings.verbosity = 3\n",
    "    \n",
    "    print(f\"CUDA used: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    adata_file_path = os.path.join(tardis.config.io_directories[\"processed\"], \"cpa_Norman2019_prep_new.h5ad\")\n",
    "    assert os.path.isfile(adata_file_path), f\"File not already exist: `{adata_file_path}`\"\n",
    "    adata = ad.read_h5ad(adata_file_path)\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X = adata.layers[\"counts\"].copy()\n",
    "del adata.layers\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_epoch_range = [12, 48]\n",
    "# _, n_epochs_kl_warmup = warmup_epoch_range\n",
    "n_epochs_kl_warmup = 400\n",
    "\n",
    "counteractive_minibatch_settings = dict(\n",
    "    method = \"categorical_random\",\n",
    "    method_kwargs = dict(\n",
    "        within_labels = False,\n",
    "        within_batch = False,\n",
    "        within_categorical_covs = None,\n",
    "        seed = \"forward\",\n",
    "    )\n",
    ")\n",
    "\n",
    "disentenglement_targets_configurations=[\n",
    "    dict(\n",
    "        obs_key = \"condition\",\n",
    "        n_reserved_latent = 8,\n",
    "        counteractive_minibatch_settings = counteractive_minibatch_settings,\n",
    "        auxillary_losses = [\n",
    "            dict(\n",
    "                apply = True, \n",
    "                target_type=\"categorical\",\n",
    "                progress_bar = True,\n",
    "                weight = 100,\n",
    "                method = \"mse_z\", \n",
    "                latent_group = \"reserved\",\n",
    "                counteractive_example = \"negative\",\n",
    "                transformation = \"inverse\", \n",
    "                warmup_epoch_range=warmup_epoch_range,\n",
    "                method_kwargs = {}\n",
    "            ),\n",
    "            dict(\n",
    "                apply = True, \n",
    "                target_type=\"categorical\",\n",
    "                progress_bar = True,\n",
    "                weight = 10, \n",
    "                method = \"mse_z\", \n",
    "                latent_group = \"reserved\",\n",
    "                counteractive_example = \"positive\",\n",
    "                transformation = \"none\",\n",
    "                warmup_epoch_range=warmup_epoch_range,\n",
    "                method_kwargs = {}\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "]\n",
    "\n",
    "model_params = dict(\n",
    "    n_hidden=512,\n",
    "    n_layers=3, \n",
    "    n_latent=32, \n",
    "    gene_likelihood = \"nb\",\n",
    "    use_batch_norm = \"none\",\n",
    "    use_layer_norm = \"both\",\n",
    "    dropout_rate = 0.1,\n",
    "    include_auxillary_loss = True\n",
    ")\n",
    "\n",
    "train_params = dict(\n",
    "    max_epochs=1000,\n",
    "    train_size=0.8,\n",
    "    batch_size=512,\n",
    "    check_val_every_n_epoch=10,\n",
    "    learning_rate_monitor=True,\n",
    "    # early stopping:\n",
    "    early_stopping=True,\n",
    "    early_stopping_patience=150,\n",
    "    early_stopping_monitor=\"elbo_train\",\n",
    "    plan_kwargs = dict(\n",
    "        n_epochs_kl_warmup=n_epochs_kl_warmup,\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-6,\n",
    "        # optimizer=\"AdamW\"\n",
    "        # lr-scheduler:\n",
    "        reduce_lr_on_plateau=True,\n",
    "        lr_patience=100,\n",
    "        lr_scheduler_metric=\"elbo_train\",\n",
    "    )\n",
    ")\n",
    "\n",
    "dataset_params = dict(\n",
    "    layer=None, \n",
    "    labels_key=None,\n",
    "    batch_key=None,\n",
    "    categorical_covariate_keys=None,\n",
    "    disentenglement_targets_configurations=disentenglement_targets_configurations\n",
    ")\n",
    "\n",
    "tardis.MyModel.setup_anndata(adata, **dataset_params)\n",
    "\n",
    "tardis.MyModel.setup_wandb(\n",
    "    wandb_configurations=tardis.config.wandb,\n",
    "    hyperparams=dict(\n",
    "        model_params=model_params,\n",
    "        train_params=train_params,\n",
    "        dataset_params=dataset_params,\n",
    "    )\n",
    ")\n",
    "\n",
    "vae = tardis.MyModel(adata, **model_params)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "    vae.train(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.join(\n",
    "    tardis.config.io_directories[\"models\"],\n",
    "    \"run13\"\n",
    ")\n",
    "\n",
    "vae.save(\n",
    "    dir_path,\n",
    "    overwrite=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_path = os.path.join(\n",
    "#     tardis.config.io_directories[\"models\"],\n",
    "#     \"run12\"\n",
    "# )\n",
    "# vae12 = tardis.MyModel.load(dir_path, adata=adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.plot_training_history(\n",
    "    ignore_first=50, \n",
    "    n_col=4,\n",
    "    metrics_name=[\n",
    "        \"reconstruction_loss\", \"kl_local\", \"elbo\", \"total_loss\",\n",
    "        #\n",
    "        \"tardis_condition_0_weighted\", \n",
    "        \"tardis_condition_0\",\n",
    "        \"tardis_condition_1_weighted\", \n",
    "        \"tardis_condition_1\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tardis._disentenglementtargetmanager import DisentenglementTargetManager\n",
    "# display(np.array(DisentenglementTargetManager.configurations.get_by_obs_key(\"age\").reserved_latent_indices))\n",
    "# display(np.array(DisentenglementTargetManager.configurations.get_by_obs_key(\"sex\").reserved_latent_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae.plot_latent_kde(\n",
    "#     adata_obs=adata.obs,\n",
    "#     target_obs_key=\"sex\",\n",
    "#     latent_representation=vae.get_latent_representation(),\n",
    "#     latent_dim_of_interest=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_vae_metrics = 512\n",
    "vae_metrics = {\n",
    "    \"reconstruction_error\": vae.get_reconstruction_error(batch_size=batch_size_vae_metrics)['reconstruction_loss'],\n",
    "    \"elbo\": vae.get_elbo(batch_size=batch_size_vae_metrics).item(),\n",
    "    \"r2_train\": vae.get_reconstruction_r2(batch_size=batch_size_vae_metrics, indices=vae.train_indices),\n",
    "    # \"r2_train_deg_20\": vae.get_reconstruction_r2(top_n_differentially_expressed_genes=20, batch_size=batch_size_vae_metrics, indices=vae.train_indices),\n",
    "    # \"r2_train_deg_50\": vae.get_reconstruction_r2(top_n_differentially_expressed_genes=50, batch_size=batch_size_vae_metrics, indices=vae.train_indices),\n",
    "    \"r2_validation\": vae.get_reconstruction_r2(batch_size=batch_size_vae_metrics, indices=vae.validation_indices),\n",
    "    # \"r2_validation_deg_20\": vae.get_reconstruction_r2(top_n_differentially_expressed_genes=20, batch_size=batch_size_vae_metrics, indices=vae.validation_indices),\n",
    "    # \"r2_validation_deg_50\": vae.get_reconstruction_r2(top_n_differentially_expressed_genes=50, batch_size=batch_size_vae_metrics, indices=vae.validation_indices),\n",
    "}\n",
    "for k, v in vae_metrics.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(ad_latent):\n",
    "    sc.pp.neighbors(ad_latent, n_neighbors = 30)\n",
    "    sc.tl.umap(ad_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = ad.AnnData(X=vae.get_latent_representation(), obs=adata.obs.copy())\n",
    "prepare(latent)\n",
    "latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_colors(num_colors):\n",
    "    return [\"#\"+''.join([np.random.choice(list('0123456789ABCDEF')) for j in range(6)]) for i in range(num_colors)]\n",
    "unique_cell_types = latent.obs[\"condition\"].unique()\n",
    "# Generate random colors for each unique cell type\n",
    "random_colors = generate_random_colors(len(unique_cell_types))\n",
    "# Create a dictionary to map cell types to colors\n",
    "color_map = dict(zip(unique_cell_types, random_colors))\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sc.pl.umap(\n",
    "        latent, \n",
    "        color=[\"condition\"], \n",
    "        ncols=1,\n",
    "        size=8,\n",
    "        frameon=False,\n",
    "        palette=color_map,\n",
    "        legend_loc=\"on data\",\n",
    "        legend_fontsize=6,\n",
    "        legend_fontweight='bold',\n",
    "        ax=plt.gca(),\n",
    "    show=False\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del latent\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
