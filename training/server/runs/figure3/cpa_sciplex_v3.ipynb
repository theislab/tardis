{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a174ddf-1bac-4261-a2df-155cc7e8fc31",
   "metadata": {},
   "source": [
    "# Afriat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd13e0f4-b441-4653-bf08-f2812d58f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d362b42-a27d-486f-9c83-f52a59bfc6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import copy\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "sys.path.append(\"/home/icb/kemal.inecik/work/codes/tardis\")\n",
    "import tardis\n",
    "tardis.config = tardis.config_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e834108-5b88-402d-94c9-c8002c7a927a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA used: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA used: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a8fa63-54f9-4cc9-aa2c-e2f1ce8ec9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "_rcparams_path = \"/home/icb/kemal.inecik/work/codes/tardis/training/local/figures/rcparams.pickle\"\n",
    "with open(_rcparams_path, 'rb') as file:\n",
    "    _rcparams = pickle.load(file)\n",
    "plt.rcParams.update(_rcparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea9ee642-93ef-4cbc-b83c-5e9f16122b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_file_path = os.path.join(tardis.config.io_directories[\"processed\"], \"cpa_GSM_new.h5ad\")\n",
    "assert os.path.isfile(adata_file_path), f\"File not already exist: `{adata_file_path}`\"\n",
    "adata = ad.read_h5ad(adata_file_path)\n",
    "\n",
    "adata.X = adata.layers[\"counts\"].copy()\n",
    "del adata.layers\n",
    "adata.obs.loc[adata.obs[\"dose\"] == \"0.0\", \"dose_val\"] = 0.0\n",
    "d = {i: ind for ind, i in enumerate(sorted(adata.obs[\"dose\"].astype(float).unique()))}\n",
    "adata.obs[\"dose_training\"] = [d[float(i)] for i in adata.obs[\"dose\"]]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd461c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_level_metrics = [\n",
    "    dict(\n",
    "        metric_identifier = \"metric_mi|dose_training\",\n",
    "        training_set = [\"train\", \"validation\"],\n",
    "        every_n_epoch = 5,\n",
    "        subsample = 1.0,\n",
    "        progress_bar = True,\n",
    "        metric_kwargs = dict(\n",
    "            variation = \"normalized\",\n",
    "            discretization_bins = 256,\n",
    "            latent_subset=None,\n",
    "            reduce=np.mean\n",
    "        )\n",
    "    ),\n",
    "    dict(\n",
    "        metric_identifier = \"metric_mi|condition\",\n",
    "        training_set = [\"train\", \"validation\"],\n",
    "        every_n_epoch = 5,\n",
    "        subsample = 1.0,\n",
    "        progress_bar = True,\n",
    "        metric_kwargs = dict(\n",
    "            variation = \"normalized\",\n",
    "            discretization_bins = 256,\n",
    "            latent_subset=None,\n",
    "            reduce=np.mean\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c43333cc-9e19-469f-8452-11ff5ee08db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_epoch_range = [6, 48]\n",
    "dtc_w1 = 100\n",
    "dtc_w2 = 10\n",
    "\n",
    "counteractive_minibatch_settings = dict(\n",
    "    method = \"categorical_random\",\n",
    "    method_kwargs = dict(\n",
    "        within_labels = False,\n",
    "        within_batch = False,\n",
    "        within_categorical_covs = None,\n",
    "        seed = \"forward\",\n",
    "    )\n",
    ")\n",
    "\n",
    "disentenglement_targets_configurations=[\n",
    "    dict(\n",
    "        obs_key = \"dose_training\",\n",
    "        n_reserved_latent = 8,\n",
    "        counteractive_minibatch_settings = counteractive_minibatch_settings,\n",
    "        auxillary_losses = [\n",
    "            dict(\n",
    "                apply = True, \n",
    "                target_type=\"pseudo_categorical\",\n",
    "                non_categorical_coefficient_method=\"squared_difference\",\n",
    "                progress_bar = False,\n",
    "                weight = dtc_w1,\n",
    "                method = \"mse_z\", \n",
    "                latent_group = \"reserved\",\n",
    "                counteractive_example = \"negative\",\n",
    "                transformation = \"inverse\", \n",
    "                warmup_epoch_range=warmup_epoch_range,\n",
    "                method_kwargs = {}\n",
    "            ),\n",
    "            dict(\n",
    "                apply = True, \n",
    "                target_type=\"categorical\",\n",
    "                progress_bar = False,\n",
    "                weight = dtc_w2, \n",
    "                method = \"mse_z\", \n",
    "                latent_group = \"reserved\",\n",
    "                counteractive_example = \"positive\",\n",
    "                transformation = \"none\",\n",
    "                warmup_epoch_range=warmup_epoch_range,\n",
    "                method_kwargs = {}\n",
    "            ),\n",
    "            dict(\n",
    "                apply = True, \n",
    "                target_type=\"categorical\",\n",
    "                progress_bar = False,\n",
    "                weight = dtc_w2 * 1,\n",
    "                method = \"mse_z\", \n",
    "                latent_group = \"unreserved_complete\",\n",
    "                counteractive_example = \"negative\",\n",
    "                transformation = \"none\", \n",
    "                warmup_epoch_range=warmup_epoch_range,\n",
    "                method_kwargs = {}\n",
    "            ),\n",
    "            dict(\n",
    "                apply = True, \n",
    "                target_type=\"categorical\",\n",
    "                progress_bar = False,\n",
    "                weight = dtc_w1 * 1, \n",
    "                method = \"mse_z\", \n",
    "                latent_group = \"unreserved_complete\",\n",
    "                counteractive_example = \"positive\",\n",
    "                transformation = \"inverse\",\n",
    "                warmup_epoch_range=warmup_epoch_range,\n",
    "                method_kwargs = {}\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    dict(\n",
    "        obs_key = \"condition\",\n",
    "        n_reserved_latent = 8,\n",
    "        counteractive_minibatch_settings = counteractive_minibatch_settings,\n",
    "        auxillary_losses = [\n",
    "            dict(\n",
    "                apply = True, \n",
    "                target_type=\"categorical\",\n",
    "                progress_bar = False,\n",
    "                weight = dtc_w1,\n",
    "                method = \"mse_z\", \n",
    "                latent_group = \"reserved\",\n",
    "                counteractive_example = \"negative\",\n",
    "                transformation = \"inverse\", \n",
    "                warmup_epoch_range=warmup_epoch_range,\n",
    "                method_kwargs = {}\n",
    "            ),\n",
    "            dict(\n",
    "                apply = True, \n",
    "                target_type=\"categorical\",\n",
    "                progress_bar = False,\n",
    "                weight = dtc_w2, \n",
    "                method = \"mse_z\", \n",
    "                latent_group = \"reserved\",\n",
    "                counteractive_example = \"positive\",\n",
    "                transformation = \"none\",\n",
    "                warmup_epoch_range=warmup_epoch_range,\n",
    "                method_kwargs = {}\n",
    "            ),\n",
    "            dict(\n",
    "                apply = True, \n",
    "                target_type=\"categorical\",\n",
    "                progress_bar = False,\n",
    "                weight = dtc_w2 * 1,\n",
    "                method = \"mse_z\", \n",
    "                latent_group = \"unreserved_complete\",\n",
    "                counteractive_example = \"negative\",\n",
    "                transformation = \"none\", \n",
    "                warmup_epoch_range=warmup_epoch_range,\n",
    "                method_kwargs = {}\n",
    "            ),\n",
    "            dict(\n",
    "                apply = True, \n",
    "                target_type=\"categorical\",\n",
    "                progress_bar = False,\n",
    "                weight = dtc_w1 * 1, \n",
    "                method = \"mse_z\", \n",
    "                latent_group = \"unreserved_complete\",\n",
    "                counteractive_example = \"positive\",\n",
    "                transformation = \"inverse\",\n",
    "                warmup_epoch_range=warmup_epoch_range,\n",
    "                method_kwargs = {}\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1962de-51e8-453c-907a-b338c1f82f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B logger initialized with the following parameters: \n",
      "Entity: inecik-academic\n",
      "Project: tardis_figures\n",
      "ID: fmqizh80\n",
      "Name: usual-cosmos-150\n",
      "Tags: tardis, conference, figures, final\n",
      "Notes: Final runs for Tardis before conference.\n",
      "URL: https://wandb.ai/inecik-academic/tardis_figures/runs/fmqizh80\n",
      "Directory: /lustre/groups/ml01/workspace/kemal.inecik/wandb/run-20240503_170624-fmqizh80/files\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/kemal.inecik/tools/apps/mamba/envs/tardis_env/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:168: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/icb/kemal.inecik/tools/apps/mamba/envs/tardis_ ...\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "/home/icb/kemal.inecik/tools/apps/mamba/envs/tardis_env/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:168: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/icb/kemal.inecik/tools/apps/mamba/envs/tardis_ ...\n",
      "/home/icb/kemal.inecik/tools/apps/mamba/envs/tardis_env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600:   0%|                                                                                                                                                                                                                                                       | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/kemal.inecik/work/codes/tardis/tardis/_counteractivegenerator.py:237: UserWarning: Possible group definition indices are calculated for `dose_training` for `training` set. Number of elements in each group: 1753,1581,1454,1704,1423,1532,1411,991\n",
      "  possible_indices = CachedPossibleGroupDefinitionIndices.get(\n",
      "/home/icb/kemal.inecik/work/codes/tardis/tardis/_counteractivegenerator.py:237: UserWarning: Possible group definition indices are calculated for `condition` for `training` set. Number of elements in each group: 1552,3571,2217,2756,1753\n",
      "  possible_indices = CachedPossibleGroupDefinitionIndices.get(\n",
      "/home/icb/kemal.inecik/work/codes/tardis/tardis/_counteractivegenerator.py:237: UserWarning: Possible group definition indices are calculated for `dose_training` for `validation` set. Number of elements in each group: 402,380,338,467,367,408,356,244\n",
      "  possible_indices = CachedPossibleGroupDefinitionIndices.get(\n",
      "/home/icb/kemal.inecik/work/codes/tardis/tardis/_counteractivegenerator.py:237: UserWarning: Possible group definition indices are calculated for `condition` for `validation` set. Number of elements in each group: 387,897,543,733,402\n",
      "  possible_indices = CachedPossibleGroupDefinitionIndices.get(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/600:  17%|█████████████████▌                                                                                       | 100/600 [16:24<1:25:14, 10.23s/it, v_num=80_1, total_loss_train=2.18e+3, kl_local_train=171, metric_mi|dose_training_train=0.226, metric_mi|condition_train=0.248]"
     ]
    }
   ],
   "source": [
    "n_epochs_kl_warmup = 600\n",
    "\n",
    "model_params = dict(\n",
    "    n_hidden=512,\n",
    "    n_layers=3, \n",
    "    n_latent=(8 + 8 * len(disentenglement_targets_configurations)),\n",
    "    gene_likelihood = \"nb\",\n",
    "    use_batch_norm = \"none\",\n",
    "    use_layer_norm = \"both\",\n",
    "    dropout_rate = 0.25,\n",
    "    deeply_inject_disentengled_latents = True,\n",
    "    include_auxillary_loss = True,\n",
    "    beta_kl_weight = 0.5,\n",
    "    encode_covariates=True\n",
    ")\n",
    "\n",
    "train_params = dict(\n",
    "    max_epochs=600,\n",
    "    train_size=0.8,\n",
    "    batch_size=128,\n",
    "    check_val_every_n_epoch=10,\n",
    "    limit_train_batches=1.0, \n",
    "    limit_val_batches=1.0,\n",
    "    learning_rate_monitor=True,\n",
    "    # early stopping:\n",
    "    early_stopping=False,\n",
    "    early_stopping_patience=150,\n",
    "    early_stopping_monitor=\"elbo_train\",\n",
    "    plan_kwargs = dict(\n",
    "        n_epochs_kl_warmup=n_epochs_kl_warmup,\n",
    "        lr=1e-4,\n",
    "        weight_decay=1e-4,\n",
    "        optimizer=\"AdamW\",\n",
    "        # lr-scheduler:\n",
    "        reduce_lr_on_plateau=True,\n",
    "        lr_patience=100,\n",
    "        lr_scheduler_metric=\"elbo_train\",\n",
    "    )\n",
    ")\n",
    "\n",
    "dataset_params = dict(\n",
    "    layer=None, \n",
    "    labels_key=None,\n",
    "    batch_key=None,\n",
    "    categorical_covariate_keys=None,\n",
    "    disentenglement_targets_configurations=disentenglement_targets_configurations,\n",
    "    model_level_metrics=model_level_metrics,\n",
    "    model_level_metrics_helper_covariates=['condition', 'dose_training']\n",
    ")\n",
    "\n",
    "tardis.MyModel.setup_anndata(adata, **dataset_params)\n",
    "dataset_params[\"adata_path\"] = adata_file_path\n",
    "dataset_params[\"adata\"] = os.path.split(adata_file_path)[1]\n",
    "\n",
    "# tardis.MyModel.setup_wandb(\n",
    "#     wandb_configurations=tardis.config.wandb,\n",
    "#     hyperparams=dict(\n",
    "#         model_params=model_params,\n",
    "#         train_params=train_params,\n",
    "#         dataset_params=dataset_params,\n",
    "#     )\n",
    "# )\n",
    "\n",
    "vae = tardis.MyModel(\n",
    "    adata,\n",
    "    **model_params\n",
    ")\n",
    "vae.train(**train_params)\n",
    "\n",
    "dir_path = os.path.join(\n",
    "    tardis.config.io_directories[\"models\"],\n",
    "    \"cpa_sciplex_v3\"\n",
    ")\n",
    "\n",
    "vae.save(\n",
    "    dir_path,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc4f365-b7a0-4c4d-92b9-993c53327048",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.get_reconstruction_r2_training(top_n=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b0307-9421-490b-8024-0c6bda8c18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"validation\"] = \"train\"\n",
    "adata.obs[\"validation\"].iloc[vae.validation_indices] = \"validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04982e03-16d4-4a56-894b-5b1ff00f5655",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.plot_training_history(\n",
    "    ignore_first=0,\n",
    "    n_col=4,\n",
    "    metrics_name=[\"metric_mi|dose_training\", \"metric_mi|condition\", \n",
    "                 \"reconstruction_loss\", \"kl_local\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd6d863-6767-4d28-b837-3c0315ba9fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tardis._disentanglementmanager import DisentanglementManager as DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7ba4f6-ba59-46dc-a35e-64b7aa078e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "sublatent = DM.configurations.get_by_obs_key(\"dose_training\").reserved_latent_indices\n",
    "latent = ad.AnnData(X=vae.get_latent_representation()[:, sublatent], obs=adata.obs.copy())\n",
    "sc.pp.neighbors(latent)\n",
    "sc.tl.umap(latent)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    sc.pl.umap(\n",
    "        latent, \n",
    "        color=['dose_training', 'condition', 'dose', \"validation\"], \n",
    "        ncols=3,\n",
    "        frameon=False,\n",
    "        legend_fontsize=\"xx-small\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a407a0d-f217-412d-b1db-804ab5f3d42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sublatent = DM.configurations.get_by_obs_key(\"condition\").reserved_latent_indices\n",
    "latent = ad.AnnData(X=vae.get_latent_representation()[:, sublatent], obs=adata.obs.copy())\n",
    "sc.pp.neighbors(latent)\n",
    "sc.tl.umap(latent)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    sc.pl.umap(\n",
    "        latent, \n",
    "        color=['dose_training', 'condition', 'dose', \"validation\"], \n",
    "        ncols=3,\n",
    "        frameon=False,\n",
    "        legend_fontsize=\"xx-small\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462de488-c98d-4b0f-9fe8-b1fa33848cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sublatent = DM.configurations.unreserved_latent_indices\n",
    "latent = ad.AnnData(X=vae.get_latent_representation()[:, sublatent], obs=adata.obs.copy())\n",
    "sc.pp.neighbors(latent)\n",
    "sc.tl.umap(latent)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    sc.pl.umap(\n",
    "        latent, \n",
    "        color=['dose_training', 'condition', 'dose', \"validation\"], \n",
    "        ncols=3,\n",
    "        frameon=False,\n",
    "        legend_fontsize=\"xx-small\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22710fb8-6c76-4e95-8290-6eff478ad7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = ad.AnnData(X=vae.get_latent_representation(), obs=adata.obs.copy())\n",
    "sc.pp.neighbors(latent)\n",
    "sc.tl.umap(latent)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    sc.pl.umap(\n",
    "        latent, \n",
    "        color=['dose_training', 'condition', 'dose', \"validation\"], \n",
    "        ncols=3,\n",
    "        frameon=False,\n",
    "        legend_fontsize=\"xx-small\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a4d71-7f61-4559-abad-f940973fee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670232e0-8d4e-4ce6-bc14-cb03124231e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
